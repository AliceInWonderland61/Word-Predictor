import torch
import torch.nn.functional as F
from transformers import AutoModelForCausalLM, AutoTokenizer
import gradio as gr

# üçì 1Ô∏è‚É£ Load model + tokenizer
model_name = "gpt2"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# üçì 2Ô∏è‚É£ Function that predicts top 5 next words for each token
def predict_next_words(text):
    if not text.strip():
        return """
        <div class='response-box'>
            <span class='response-label'>Predicted Next Tokens üçì</span>
            <p class='placeholder-text'>Type something above to see predictions üíï</p>
        </div>
        """

    inputs = tokenizer(text, return_tensors="pt")
    input_ids = inputs["input_ids"][0]
    results_html = ["<table class='prediction-table'>"]

    # üßÅ Add header row
    results_html.append("<tr><th>Token</th><th>Top 5 Predictions</th></tr>")

    for i in range(len(input_ids)):
        prefix = input_ids[:i + 1].unsqueeze(0)
        with torch.no_grad():
            outputs = model(prefix)
            logits = outputs.logits[:, -1, :]
            probs = F.softmax(logits, dim=-1)
            topk = torch.topk(probs, k=5)
            top_tokens = [tokenizer.decode([tid]).strip() for tid in topk.indices[0]]

        current_token = tokenizer.decode([input_ids[i]]).strip() or "(space)"
        preds = ", ".join(top_tokens)
        results_html.append(f"<tr><td class='token-cell'>{current_token}</td><td class='pred-cell'>{preds}</td></tr>")

    results_html.append("</table>")

    return f"""
    <div class='response-box'>
        <span class='response-label'>Predicted Next Tokens üçì</span>
        {''.join(results_html)}
    </div>
    """

# üçì 3Ô∏è‚É£ Custom CSS ‚Äî cute, readable, and clear output box
custom_css = """
body {
    background: linear-gradient(180deg, #fff8fa 0%, #ffe6eb 35%, #ffd6e0 100%);
    background-attachment: fixed;
}
.gradio-container {
    background: transparent !important;
}
textarea, input {
    background-color: #fffdfd !important;
    color: #5a3d3d !important;
    border-radius: 20px !important;
    border: 2px solid #ffc9d6 !important;
    font-size: 16px !important;
    padding: 8px !important;
}
button {
    background: linear-gradient(90deg, #ffb6c1, #ff9eb0);
    color: white !important;
    border-radius: 12px !important;
    font-weight: bold !important;
    transition: 0.3s ease;
}
button:hover {
    background: linear-gradient(90deg, #ff9eb0, #ffb6c1);
}

/* üçì Output box styling (persistent) */
.response-box {
    background-color: rgba(255, 230, 235, 0.9);
    border: 2px solid #ffb6c1;
    border-radius: 15px;
    padding: 20px;
    color: #4b2b30;
    font-size: 16px;
    line-height: 1.6;
    margin-top: 15px;
    box-shadow: 3px 4px 8px rgba(255, 182, 193, 0.3);
    white-space: pre-wrap;
    min-height: 150px;
    width: 100%;
}
.response-label {
    font-weight: bold;
    color: #d36b83;
    font-size: 18px;
    font-family: "Poppins", sans-serif;
    margin-bottom: 8px;
    display: block;
    border-bottom: 1.5px dashed #ffc9d6;
    padding-bottom: 5px;
    text-align: center;
}
/* üç∞ Force the output box to always show */
#output-box {
    display: block !important;
    width: 100%;
}
h1, h3 {
    color: #d36b83;
    font-family: "Comic Sans MS", "Poppins", sans-serif;
    text-align: center;
}

/* üçì Table styling for predictions */
.prediction-table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 10px;
}
.prediction-table th {
    background-color: #ffe6eb;
    color: #d36b83;
    text-align: center;
    font-family: "Poppins", sans-serif;
    padding: 6px;
    border-bottom: 2px dashed #ffc9d6;
}
.prediction-table td {
    padding: 6px 10px;
    color: #4b2b30;
    border-bottom: 1px solid #ffd3de;
    vertical-align: top;
}
.token-cell {
    font-weight: bold;
    text-align: right;
    width: 25%;
    color: #c45c77;
    padding-right: 10px;
}
.pred-cell {
    text-align: left;
    font-style: italic;
    width: 75%;
}
.placeholder-text {
    text-align: center;
    color: #a86a7a;
    font-style: italic;
    margin-top: 8px;
}
"""

# üçì 4Ô∏è‚É£ Build the Gradio UI
demo = gr.Blocks(css=custom_css)

with demo:
    gr.HTML("<h1>üçì Word Predictor üçì</h1><h3>Type a sweet sentence and see what the AI thinks comes next!</h3>")
    text_input = gr.Textbox(
        placeholder="Type your text here... üç∞",
        label="Your Text üíå"
    )

    with gr.Row():
        output = gr.HTML(
            value="""
            <div class='response-box'>
                <span class='response-label'>Predicted Next Tokens üçì</span>
                <p class='placeholder-text'>Type something above to see predictions üíï</p>
            </div>
            """,
            elem_id="output-box",
            label="Generated Response üçì",
            show_label=False
        )

    generate_btn = gr.Button("‚ú® Predict Next Words ‚ú®")
    generate_btn.click(predict_next_words, inputs=text_input, outputs=output)
    gr.HTML("<p style='text-align:center;color:#c07085;'>Powered by üçì Effort</p>")

# üçì 5Ô∏è‚É£ Launch
if __name__ == "__main__":
    demo.launch()
